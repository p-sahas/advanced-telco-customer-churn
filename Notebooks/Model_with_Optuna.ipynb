{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development with Optuna Hyperparameter Tuning\n",
    "\n",
    "This notebook implements hyperparameter tuning using Optuna for the following models:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "\n",
    "The data processing and SMOTE application match the original `03_model_deploment.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5634, 50)\n",
      "Test shape: (1409, 50)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Seperate features and target\n",
    "target = 'Churn'\n",
    "X_train_ber_res = train_df.drop(target, axis=1)\n",
    "y_train_ber_res = train_df[target]\n",
    "X_test = test_df.drop(target, axis=1)\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution: Counter({0: 4139, 1: 1495})\n",
      "Resampled Class Distribution: Counter({0: 4139, 1: 4139})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Class Distribution:\", Counter(y_train_ber_res))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train, y_train = smote.fit_resample(X_train_ber_res, y_train_ber_res)\n",
    "\n",
    "print(\"Resampled Class Distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optuna Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs', 'saga'])\n",
    "    \n",
    "    # penalty depends on solver\n",
    "    if solver == 'liblinear':\n",
    "        penalty = trial.suggest_categorical('penalty_liblinear', ['l1', 'l2'])\n",
    "    elif solver == 'saga':\n",
    "        penalty = trial.suggest_categorical('penalty_saga', ['l1', 'l2', 'elasticnet'])\n",
    "    else:\n",
    "        penalty = 'l2'\n",
    "        \n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        C=C, \n",
    "        solver=solver, \n",
    "        penalty=penalty, \n",
    "        l1_ratio=l1_ratio,\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=1000\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_dt(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=criterion,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 12)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    \n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        gamma=gamma,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_cat(trial):\n",
    "    iterations = trial.suggest_int('iterations', 50, 500)\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 10)\n",
    "    \n",
    "    clf = CatBoostClassifier(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        random_seed=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "        thread_count=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:38:34,808] A new study created in memory with name: no-name-59c4ab5f-5fae-4fbb-99ed-bf793f60e756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:38:35,542] Trial 0 finished with value: 0.691739393206101 and parameters: {'C': 0.0001676000830578636, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.15705954525117083}. Best is trial 0 with value: 0.691739393206101.\n",
      "[I 2026-01-20 20:38:37,132] Trial 1 finished with value: 0.8481832272591083 and parameters: {'C': 8.290975066560094, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8481832272591083.\n",
      "[I 2026-01-20 20:39:17,905] Trial 2 finished with value: 0.8480637938962934 and parameters: {'C': 7.823844921673912, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 1 with value: 0.8481832272591083.\n",
      "[I 2026-01-20 20:39:42,802] Trial 3 finished with value: 0.8480463282397345 and parameters: {'C': 10.997699606756548, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 1 with value: 0.8481832272591083.\n",
      "[I 2026-01-20 20:39:43,632] Trial 4 finished with value: 0.8481736743213357 and parameters: {'C': 1.6428505674208596, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8481832272591083.\n",
      "[I 2026-01-20 20:39:43,798] Trial 5 finished with value: 0.0 and parameters: {'C': 0.00010413858831082783, 'solver': 'liblinear', 'penalty_liblinear': 'l1'}. Best is trial 1 with value: 0.8481832272591083.\n",
      "[I 2026-01-20 20:39:44,392] Trial 6 finished with value: 0.849655788568765 and parameters: {'C': 0.4521096967964931, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:44,691] Trial 7 finished with value: 0.8349270912557809 and parameters: {'C': 0.28032277433354463, 'solver': 'liblinear', 'penalty_liblinear': 'l2'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:45,285] Trial 8 finished with value: 0.7889491762037849 and parameters: {'C': 0.0031415533262941424, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:45,992] Trial 9 finished with value: 0.7872542835349322 and parameters: {'C': 0.004848450570914818, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.17991205927725973}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:47,187] Trial 10 finished with value: 0.8484448310692164 and parameters: {'C': 86.8372237111403, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:48,373] Trial 11 finished with value: 0.848132215618975 and parameters: {'C': 48.107312719211755, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:48,678] Trial 12 finished with value: 0.8308706352131378 and parameters: {'C': 0.035644632161270104, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:49,177] Trial 13 finished with value: 0.8478132575101469 and parameters: {'C': 0.2677389723897663, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:49,894] Trial 14 finished with value: 0.8495919520811501 and parameters: {'C': 1.0246105902211375, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:50,617] Trial 15 finished with value: 0.8495246329262912 and parameters: {'C': 1.142881979209633, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:50,960] Trial 16 finished with value: 0.8323005762549622 and parameters: {'C': 0.03965452241373437, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:51,311] Trial 17 finished with value: 0.84537522135283 and parameters: {'C': 1.0565400074912765, 'solver': 'liblinear', 'penalty_liblinear': 'l2'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:51,565] Trial 18 finished with value: 0.8010739549523533 and parameters: {'C': 0.008380154070900887, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:52,015] Trial 19 finished with value: 0.8469676729476439 and parameters: {'C': 0.16450189724931896, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.849655788568765.\n",
      "[I 2026-01-20 20:39:52,015] A new study created in memory with name: no-name-235338e5-7096-4375-a309-166a7085a99a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Logistic Regression: {'C': 0.4521096967964931, 'solver': 'lbfgs'}\n",
      "Optimizing Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:39:52,286] Trial 0 finished with value: 0.7914493037419106 and parameters: {'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'gini'}. Best is trial 0 with value: 0.7914493037419106.\n",
      "[I 2026-01-20 20:39:52,657] Trial 1 finished with value: 0.8031343784146276 and parameters: {'max_depth': 18, 'min_samples_split': 14, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 1 with value: 0.8031343784146276.\n",
      "[I 2026-01-20 20:39:53,104] Trial 2 finished with value: 0.7944670700250701 and parameters: {'max_depth': 19, 'min_samples_split': 20, 'min_samples_leaf': 12, 'criterion': 'entropy'}. Best is trial 1 with value: 0.8031343784146276.\n",
      "[I 2026-01-20 20:39:53,542] Trial 3 finished with value: 0.7959939265683685 and parameters: {'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 20, 'criterion': 'entropy'}. Best is trial 1 with value: 0.8031343784146276.\n",
      "[I 2026-01-20 20:39:53,892] Trial 4 finished with value: 0.8035976585168854 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 9, 'criterion': 'gini'}. Best is trial 4 with value: 0.8035976585168854.\n",
      "[I 2026-01-20 20:39:54,280] Trial 5 finished with value: 0.8052264498951429 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 7, 'criterion': 'gini'}. Best is trial 5 with value: 0.8052264498951429.\n",
      "[I 2026-01-20 20:39:54,737] Trial 6 finished with value: 0.7942975951921134 and parameters: {'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 15, 'criterion': 'entropy'}. Best is trial 5 with value: 0.8052264498951429.\n",
      "[I 2026-01-20 20:39:55,068] Trial 7 finished with value: 0.8054097926177928 and parameters: {'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:55,440] Trial 8 finished with value: 0.8000338927366265 and parameters: {'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 18, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:55,802] Trial 9 finished with value: 0.8023743430859674 and parameters: {'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 17, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:56,018] Trial 10 finished with value: 0.7595717946542664 and parameters: {'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 13, 'criterion': 'entropy'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:56,395] Trial 11 finished with value: 0.8007742280596577 and parameters: {'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 7, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:56,823] Trial 12 finished with value: 0.8019293053187365 and parameters: {'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:57,173] Trial 13 finished with value: 0.8017500926992467 and parameters: {'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 8, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:57,573] Trial 14 finished with value: 0.796738471713998 and parameters: {'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 5, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:57,789] Trial 15 finished with value: 0.7909320990404709 and parameters: {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 11, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:58,134] Trial 16 finished with value: 0.8037854473400466 and parameters: {'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 14, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:58,551] Trial 17 finished with value: 0.7946369630374106 and parameters: {'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:59,017] Trial 18 finished with value: 0.7952261731199617 and parameters: {'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 10, 'criterion': 'entropy'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:59,380] Trial 19 finished with value: 0.7996529747466192 and parameters: {'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 20, 'criterion': 'gini'}. Best is trial 7 with value: 0.8054097926177928.\n",
      "[I 2026-01-20 20:39:59,381] A new study created in memory with name: no-name-4884c4c7-a067-457a-ad4a-54afbb958e72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Decision Tree: {'max_depth': 8, 'min_samples_split': 18, 'min_samples_leaf': 16, 'criterion': 'gini'}\n",
      "Optimizing RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:40:02,010] Trial 0 finished with value: 0.8296179604869757 and parameters: {'n_estimators': 235, 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8296179604869757.\n",
      "[I 2026-01-20 20:40:04,301] Trial 1 finished with value: 0.8334992297613318 and parameters: {'n_estimators': 213, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8334992297613318.\n",
      "[I 2026-01-20 20:40:07,071] Trial 2 finished with value: 0.8503197678044886 and parameters: {'n_estimators': 264, 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:09,810] Trial 3 finished with value: 0.8097460274470287 and parameters: {'n_estimators': 264, 'max_depth': 26, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:12,035] Trial 4 finished with value: 0.8097508024247836 and parameters: {'n_estimators': 213, 'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 17}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:14,444] Trial 5 finished with value: 0.7633104947889523 and parameters: {'n_estimators': 233, 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:16,680] Trial 6 finished with value: 0.8120067524120952 and parameters: {'n_estimators': 208, 'max_depth': 24, 'min_samples_split': 8, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:18,875] Trial 7 finished with value: 0.8199329976542504 and parameters: {'n_estimators': 204, 'max_depth': 25, 'min_samples_split': 11, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:20,472] Trial 8 finished with value: 0.8126475382012194 and parameters: {'n_estimators': 142, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 16}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:23,280] Trial 9 finished with value: 0.809130457075628 and parameters: {'n_estimators': 259, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.8503197678044886.\n",
      "[I 2026-01-20 20:40:24,083] Trial 10 finished with value: 0.8564943949109032 and parameters: {'n_estimators': 57, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:24,858] Trial 11 finished with value: 0.8555127552257688 and parameters: {'n_estimators': 58, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:25,575] Trial 12 finished with value: 0.8280247472217854 and parameters: {'n_estimators': 50, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:26,348] Trial 13 finished with value: 0.8563318406356332 and parameters: {'n_estimators': 51, 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:27,602] Trial 14 finished with value: 0.8237365253815896 and parameters: {'n_estimators': 104, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:28,896] Trial 15 finished with value: 0.827886047831219 and parameters: {'n_estimators': 102, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:30,444] Trial 16 finished with value: 0.8240399028613418 and parameters: {'n_estimators': 100, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.8564943949109032.\n",
      "[I 2026-01-20 20:40:32,658] Trial 17 finished with value: 0.8596805973543832 and parameters: {'n_estimators': 147, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.8596805973543832.\n",
      "[I 2026-01-20 20:40:35,518] Trial 18 finished with value: 0.8427997676144322 and parameters: {'n_estimators': 166, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.8596805973543832.\n",
      "[I 2026-01-20 20:40:39,200] Trial 19 finished with value: 0.8254811691382762 and parameters: {'n_estimators': 298, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 17 with value: 0.8596805973543832.\n",
      "[I 2026-01-20 20:40:39,201] A new study created in memory with name: no-name-434c5b9c-80f1-44d4-b36a-298807772035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'n_estimators': 147, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1}\n",
      "Optimizing XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:40:42,837] Trial 0 finished with value: 0.8561111392303623 and parameters: {'n_estimators': 103, 'max_depth': 8, 'learning_rate': 0.1558261644163302, 'subsample': 0.9971751891904992, 'colsample_bytree': 0.7457632876998302, 'gamma': 0.7710462809842539}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:47,162] Trial 1 finished with value: 0.846482901925774 and parameters: {'n_estimators': 206, 'max_depth': 6, 'learning_rate': 0.03456453563343632, 'subsample': 0.7996532469834541, 'colsample_bytree': 0.5166205030706925, 'gamma': 3.1297709121039583}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:49,395] Trial 2 finished with value: 0.8382275120165117 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.013354146890855722, 'subsample': 0.6600253287247608, 'colsample_bytree': 0.9430885321014866, 'gamma': 1.790315145979301}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:50,600] Trial 3 finished with value: 0.8406347009816013 and parameters: {'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.076417540790333, 'subsample': 0.6177605755639308, 'colsample_bytree': 0.5037126745497638, 'gamma': 4.561487200878955}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:52,162] Trial 4 finished with value: 0.8524097112043708 and parameters: {'n_estimators': 243, 'max_depth': 12, 'learning_rate': 0.2035147157664344, 'subsample': 0.6761544101255708, 'colsample_bytree': 0.5333719223859279, 'gamma': 1.5664538510421155}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:52,855] Trial 5 finished with value: 0.851001744366111 and parameters: {'n_estimators': 123, 'max_depth': 8, 'learning_rate': 0.20156002890095379, 'subsample': 0.8184763396604284, 'colsample_bytree': 0.9494129482055269, 'gamma': 2.351485007933132}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:54,015] Trial 6 finished with value: 0.8455131186336263 and parameters: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.0498812055499419, 'subsample': 0.5718434558146717, 'colsample_bytree': 0.5948922195334119, 'gamma': 3.3515364545034627}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:55,551] Trial 7 finished with value: 0.85175505351924 and parameters: {'n_estimators': 188, 'max_depth': 11, 'learning_rate': 0.03696495870331311, 'subsample': 0.8041241666552209, 'colsample_bytree': 0.7055275920638038, 'gamma': 2.742519465594399}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:57,884] Trial 8 finished with value: 0.8513894051689709 and parameters: {'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.14079569114667195, 'subsample': 0.8724800377046926, 'colsample_bytree': 0.7239097846663206, 'gamma': 0.3170819201461095}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:40:58,383] Trial 9 finished with value: 0.8276981195073927 and parameters: {'n_estimators': 69, 'max_depth': 2, 'learning_rate': 0.2084062369254389, 'subsample': 0.7294715814261424, 'colsample_bytree': 0.8886996576028504, 'gamma': 2.91341817566137}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:41:01,103] Trial 10 finished with value: 0.85492768695345 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.09530580136602768, 'subsample': 0.9829846508522689, 'colsample_bytree': 0.8375486607672226, 'gamma': 0.3816195164481871}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:41:02,395] Trial 11 finished with value: 0.8537539064004678 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.09654680771359553, 'subsample': 0.9971179544766192, 'colsample_bytree': 0.8334296600880325, 'gamma': 0.00250910585409031}. Best is trial 0 with value: 0.8561111392303623.\n",
      "[I 2026-01-20 20:41:03,565] Trial 12 finished with value: 0.8570194955421563 and parameters: {'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.1016996289793518, 'subsample': 0.9803666511057868, 'colsample_bytree': 0.7978833636408686, 'gamma': 0.693329814759654}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:04,630] Trial 13 finished with value: 0.855748305358221 and parameters: {'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.12709619004564363, 'subsample': 0.9199235916917802, 'colsample_bytree': 0.6532644005230509, 'gamma': 1.0317696552679054}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:05,406] Trial 14 finished with value: 0.8191558039966512 and parameters: {'n_estimators': 95, 'max_depth': 4, 'learning_rate': 0.02319530925168472, 'subsample': 0.8842838706073171, 'colsample_bytree': 0.7799163943214896, 'gamma': 1.0294899296515752}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:06,380] Trial 15 finished with value: 0.8558150601229365 and parameters: {'n_estimators': 157, 'max_depth': 8, 'learning_rate': 0.26628188522651036, 'subsample': 0.9431859092009386, 'colsample_bytree': 0.809201741460816, 'gamma': 1.047163295489336}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:07,852] Trial 16 finished with value: 0.8512609708498333 and parameters: {'n_estimators': 154, 'max_depth': 7, 'learning_rate': 0.060466040809830014, 'subsample': 0.939465754529655, 'colsample_bytree': 0.6629645927547074, 'gamma': 2.025570796089019}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:08,608] Trial 17 finished with value: 0.8509549848713771 and parameters: {'n_estimators': 89, 'max_depth': 5, 'learning_rate': 0.14269475246041008, 'subsample': 0.5225157499374622, 'colsample_bytree': 0.9984814141467441, 'gamma': 3.9612382849754217}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:09,995] Trial 18 finished with value: 0.8541953007889754 and parameters: {'n_estimators': 146, 'max_depth': 9, 'learning_rate': 0.28414555209940656, 'subsample': 0.8646325334678746, 'colsample_bytree': 0.7613962452743108, 'gamma': 0.7386183861735471}. Best is trial 12 with value: 0.8570194955421563.\n",
      "[I 2026-01-20 20:41:13,090] Trial 19 finished with value: 0.8585183882804558 and parameters: {'n_estimators': 92, 'max_depth': 12, 'learning_rate': 0.10533882909157204, 'subsample': 0.7437805562823132, 'colsample_bytree': 0.8630166770251131, 'gamma': 1.4428723657635838}. Best is trial 19 with value: 0.8585183882804558.\n",
      "[I 2026-01-20 20:41:13,092] A new study created in memory with name: no-name-fcb9d085-b97f-443e-9022-67cb35e7ca00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'n_estimators': 92, 'max_depth': 12, 'learning_rate': 0.10533882909157204, 'subsample': 0.7437805562823132, 'colsample_bytree': 0.8630166770251131, 'gamma': 1.4428723657635838}\n",
      "Optimizing CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-20 20:41:18,073] Trial 0 finished with value: 0.8426252923965212 and parameters: {'iterations': 196, 'depth': 6, 'learning_rate': 0.017456918181314264, 'l2_leaf_reg': 7}. Best is trial 0 with value: 0.8426252923965212.\n",
      "[I 2026-01-20 20:41:25,623] Trial 1 finished with value: 0.8508091511495727 and parameters: {'iterations': 231, 'depth': 8, 'learning_rate': 0.012835049962949503, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.8508091511495727.\n",
      "[I 2026-01-20 20:41:35,059] Trial 2 finished with value: 0.8536365554564486 and parameters: {'iterations': 257, 'depth': 8, 'learning_rate': 0.15542292500915716, 'l2_leaf_reg': 6}. Best is trial 2 with value: 0.8536365554564486.\n",
      "[I 2026-01-20 20:41:43,028] Trial 3 finished with value: 0.8480620114042906 and parameters: {'iterations': 180, 'depth': 8, 'learning_rate': 0.01834349018496999, 'l2_leaf_reg': 7}. Best is trial 2 with value: 0.8536365554564486.\n",
      "[I 2026-01-20 20:41:48,187] Trial 4 finished with value: 0.843369848068973 and parameters: {'iterations': 286, 'depth': 5, 'learning_rate': 0.01403098696454198, 'l2_leaf_reg': 5}. Best is trial 2 with value: 0.8536365554564486.\n",
      "[I 2026-01-20 20:42:10,654] Trial 5 finished with value: 0.8572222896137954 and parameters: {'iterations': 299, 'depth': 10, 'learning_rate': 0.05726725248619625, 'l2_leaf_reg': 4}. Best is trial 5 with value: 0.8572222896137954.\n",
      "[I 2026-01-20 20:42:13,365] Trial 6 finished with value: 0.8229618646281159 and parameters: {'iterations': 187, 'depth': 4, 'learning_rate': 0.014133033064672555, 'l2_leaf_reg': 7}. Best is trial 5 with value: 0.8572222896137954.\n",
      "[I 2026-01-20 20:42:41,215] Trial 7 finished with value: 0.8596852618634422 and parameters: {'iterations': 476, 'depth': 9, 'learning_rate': 0.03151373163241198, 'l2_leaf_reg': 6}. Best is trial 7 with value: 0.8596852618634422.\n",
      "[I 2026-01-20 20:42:45,846] Trial 8 finished with value: 0.830698181717742 and parameters: {'iterations': 60, 'depth': 10, 'learning_rate': 0.01196922915019013, 'l2_leaf_reg': 1}. Best is trial 7 with value: 0.8596852618634422.\n",
      "[I 2026-01-20 20:43:06,983] Trial 9 finished with value: 0.8549078520262084 and parameters: {'iterations': 270, 'depth': 10, 'learning_rate': 0.014850156058781795, 'l2_leaf_reg': 6}. Best is trial 7 with value: 0.8596852618634422.\n",
      "[I 2026-01-20 20:43:19,319] Trial 10 finished with value: 0.8558988517499619 and parameters: {'iterations': 499, 'depth': 7, 'learning_rate': 0.0468785292514266, 'l2_leaf_reg': 10}. Best is trial 7 with value: 0.8596852618634422.\n",
      "[I 2026-01-20 20:43:55,288] Trial 11 finished with value: 0.8573406565841056 and parameters: {'iterations': 476, 'depth': 10, 'learning_rate': 0.05496160143407714, 'l2_leaf_reg': 3}. Best is trial 7 with value: 0.8596852618634422.\n",
      "[I 2026-01-20 20:44:20,670] Trial 12 finished with value: 0.8608764997152086 and parameters: {'iterations': 486, 'depth': 9, 'learning_rate': 0.04468897477636859, 'l2_leaf_reg': 2}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:44:46,543] Trial 13 finished with value: 0.8607499606222208 and parameters: {'iterations': 414, 'depth': 9, 'learning_rate': 0.03635134186294391, 'l2_leaf_reg': 1}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:45:05,612] Trial 14 finished with value: 0.8501441282699428 and parameters: {'iterations': 398, 'depth': 9, 'learning_rate': 0.13987575649782252, 'l2_leaf_reg': 1}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:45:15,759] Trial 15 finished with value: 0.8534328937459258 and parameters: {'iterations': 385, 'depth': 7, 'learning_rate': 0.09125260186482456, 'l2_leaf_reg': 2}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:45:42,428] Trial 16 finished with value: 0.8492824645832863 and parameters: {'iterations': 405, 'depth': 9, 'learning_rate': 0.26910892509412476, 'l2_leaf_reg': 2}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:45:53,231] Trial 17 finished with value: 0.8591674635460124 and parameters: {'iterations': 425, 'depth': 6, 'learning_rate': 0.0286576778072165, 'l2_leaf_reg': 2}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:46:16,604] Trial 18 finished with value: 0.8597585766442438 and parameters: {'iterations': 345, 'depth': 9, 'learning_rate': 0.030025403327226734, 'l2_leaf_reg': 3}. Best is trial 12 with value: 0.8608764997152086.\n",
      "[I 2026-01-20 20:46:34,351] Trial 19 finished with value: 0.8534565196959356 and parameters: {'iterations': 443, 'depth': 8, 'learning_rate': 0.08367647490277404, 'l2_leaf_reg': 10}. Best is trial 12 with value: 0.8608764997152086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for CatBoost: {'iterations': 486, 'depth': 9, 'learning_rate': 0.04468897477636859, 'l2_leaf_reg': 2}\n",
      "\n",
      "Optimization Complete.\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_params = {}\n",
    "\n",
    "studies = {\n",
    "    'Logistic Regression': objective_lr,\n",
    "    'Decision Tree': objective_dt,\n",
    "    'RandomForest': objective_rf,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'CatBoost': objective_cat\n",
    "}\n",
    "\n",
    "for name, objective in studies.items():\n",
    "    print(f\"Optimizing {name}...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=20) # 20 trials for demonstration\n",
    "    \n",
    "    print(f\"Best params for {name}: {study.best_params}\")\n",
    "    best_models[name] = study.best_trial.value\n",
    "    best_params[name] = study.best_params\n",
    "    \n",
    "print(\"\\nOptimization Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Best Models and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.7821, F1: 0.6008\n",
      "Training best Decision Tree...\n",
      "Decision Tree - Accuracy: 0.7530, F1: 0.5787\n",
      "Training best RandomForest...\n",
      "RandomForest - Accuracy: 0.7708, F1: 0.5854\n",
      "Training best XGBoost...\n",
      "XGBoost - Accuracy: 0.7850, F1: 0.6060\n",
      "Training best CatBoost...\n",
      "CatBoost - Accuracy: 0.7750, F1: 0.5823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.782115</td>\n",
       "      <td>0.600780</td>\n",
       "      <td>{'C': 0.4521096967964931, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.753016</td>\n",
       "      <td>0.578692</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 18, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.770759</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>{'n_estimators': 147, 'max_depth': 32, 'min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.784954</td>\n",
       "      <td>0.605982</td>\n",
       "      <td>{'n_estimators': 92, 'max_depth': 12, 'learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.775018</td>\n",
       "      <td>0.582345</td>\n",
       "      <td>{'iterations': 486, 'depth': 9, 'learning_rate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score  \\\n",
       "0  Logistic Regression  0.782115  0.600780   \n",
       "1        Decision Tree  0.753016  0.578692   \n",
       "2         RandomForest  0.770759  0.585366   \n",
       "3              XGBoost  0.784954  0.605982   \n",
       "4             CatBoost  0.775018  0.582345   \n",
       "\n",
       "                                         Best Params  \n",
       "0       {'C': 0.4521096967964931, 'solver': 'lbfgs'}  \n",
       "1  {'max_depth': 8, 'min_samples_split': 18, 'min...  \n",
       "2  {'n_estimators': 147, 'max_depth': 32, 'min_sa...  \n",
       "3  {'n_estimators': 92, 'max_depth': 12, 'learnin...  \n",
       "4  {'iterations': 486, 'depth': 9, 'learning_rate...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, params in best_params.items():\n",
    "    print(f\"Training best {name}...\")\n",
    "    if name == 'Logistic Regression':\n",
    "        solver = params['solver']\n",
    "        penalty = 'l2' # Default penalty\n",
    "        l1_ratio = None\n",
    "        \n",
    "        if solver == 'lbfgs': \n",
    "            penalty = 'l2'\n",
    "            l1_ratio = None\n",
    "        elif solver == 'liblinear':\n",
    "             penalty = params.get('penalty_liblinear', 'l2') \n",
    "        elif solver == 'saga':\n",
    "             penalty = params.get('penalty_saga', 'l2')\n",
    "\n",
    "        # Handle l1_ratio for elasticnet if applicable\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = params.get('l1_ratio')\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            C=params['C'], \n",
    "            solver=solver, \n",
    "            penalty=penalty, \n",
    "            l1_ratio=l1_ratio,\n",
    "            random_state=RANDOM_STATE, \n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif name == 'Decision Tree':\n",
    "        clf = DecisionTreeClassifier(**params, random_state=RANDOM_STATE)\n",
    "    elif name == 'RandomForest':\n",
    "        clf = RandomForestClassifier(**params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    elif name == 'XGBoost':\n",
    "        clf = XGBClassifier(**params, random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False, n_jobs=-1)\n",
    "    elif name == 'CatBoost':\n",
    "        clf = CatBoostClassifier(**params, random_seed=RANDOM_STATE, verbose=0, thread_count=-1)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Best Params': str(params)\n",
    "    })\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# Visualize F1 Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='F1 Score', y='Model', data=results_df, palette='viridis')\n",
    "plt.title('Model Performance after Optuna Tuning (F1 Score)')\n",
    "plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sahas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
