{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development with Optuna Hyperparameter Tuning\n",
    "\n",
    "This notebook implements hyperparameter tuning using Optuna for the following models:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "\n",
    "The data processing and SMOTE application match the original `03_model_deploment.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5634, 50)\n",
      "Test shape: (1409, 50)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Seperate features and target\n",
    "target = 'Churn'\n",
    "X_train_ber_res = train_df.drop(target, axis=1)\n",
    "y_train_ber_res = train_df[target]\n",
    "X_test = test_df.drop(target, axis=1)\n",
    "y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution: Counter({0: 4139, 1: 1495})\n",
      "Resampled Class Distribution: Counter({0: 4139, 1: 4139})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Class Distribution:\", Counter(y_train_ber_res))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train, y_train = smote.fit_resample(X_train_ber_res, y_train_ber_res)\n",
    "\n",
    "print(\"Resampled Class Distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optuna Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs', 'saga'])\n",
    "    \n",
    "    # penalty depends on solver\n",
    "    if solver == 'liblinear':\n",
    "        penalty = trial.suggest_categorical('penalty_liblinear', ['l1', 'l2'])\n",
    "    elif solver == 'saga':\n",
    "        penalty = trial.suggest_categorical('penalty_saga', ['l1', 'l2', 'elasticnet'])\n",
    "    else:\n",
    "        penalty = 'l2'\n",
    "        \n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        C=C, \n",
    "        solver=solver, \n",
    "        penalty=penalty, \n",
    "        l1_ratio=l1_ratio,\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=1000\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_dt(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=criterion,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 12)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "    \n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        gamma=gamma,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_cat(trial):\n",
    "    iterations = trial.suggest_int('iterations', 50, 500)\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 10)\n",
    "    \n",
    "    clf = CatBoostClassifier(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        random_seed=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "        thread_count=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:35:43,687] A new study created in memory with name: no-name-dc7b0cc0-0e94-46fe-a415-a799f24b5b13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:35:43,895] Trial 0 finished with value: 0.7708177304371999 and parameters: {'C': 0.007157868790245886, 'solver': 'liblinear', 'penalty_liblinear': 'l1'}. Best is trial 0 with value: 0.7708177304371999.\n",
      "[I 2026-01-18 22:35:44,119] Trial 1 finished with value: 0.8007398193053161 and parameters: {'C': 0.007952491254378516, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.8007398193053161.\n",
      "[I 2026-01-18 22:35:44,397] Trial 2 finished with value: 0.8341477892831305 and parameters: {'C': 0.22977231669904333, 'solver': 'liblinear', 'penalty_liblinear': 'l2'}. Best is trial 2 with value: 0.8341477892831305.\n",
      "[I 2026-01-18 22:35:44,930] Trial 3 finished with value: 0.8481506918656091 and parameters: {'C': 0.2798704607010932, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.8481506918656091.\n",
      "[I 2026-01-18 22:35:45,492] Trial 4 finished with value: 0.8494815405168346 and parameters: {'C': 0.4326222201554303, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.8494815405168346.\n",
      "[I 2026-01-18 22:35:46,399] Trial 5 finished with value: 0.8483727368628603 and parameters: {'C': 5.5066657180993905, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.8494815405168346.\n",
      "[I 2026-01-18 22:35:47,060] Trial 6 finished with value: 0.8485946526839173 and parameters: {'C': 1.5532914345034774, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.8494815405168346.\n",
      "[I 2026-01-18 22:35:47,570] Trial 7 finished with value: 0.8495807342171131 and parameters: {'C': 0.4466241977543894, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:35:47,726] Trial 8 finished with value: 0.0 and parameters: {'C': 0.0006527142371364515, 'solver': 'liblinear', 'penalty_liblinear': 'l1'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:36:20,569] Trial 9 finished with value: 0.8479942755119222 and parameters: {'C': 40.566944037346815, 'solver': 'liblinear', 'penalty_liblinear': 'l1'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:36:52,481] Trial 10 finished with value: 0.8479142549728712 and parameters: {'C': 97.37394150159471, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.8403787473817604}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:36:52,729] Trial 11 finished with value: 0.8140009306206976 and parameters: {'C': 0.015129953882872839, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:02,408] Trial 12 finished with value: 0.8477068879984723 and parameters: {'C': 2.23293190288021, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:02,728] Trial 13 finished with value: 0.8367723602435231 and parameters: {'C': 0.0522442068912414, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:02,886] Trial 14 finished with value: 0.765513420019526 and parameters: {'C': 0.00014455161641462852, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:03,486] Trial 15 finished with value: 0.8491561631685197 and parameters: {'C': 0.7059045397727659, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:34,705] Trial 16 finished with value: 0.8482386997652244 and parameters: {'C': 10.074823514992557, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:35,024] Trial 17 finished with value: 0.8364355511261035 and parameters: {'C': 0.05161102016395745, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:35,209] Trial 18 finished with value: 0.78227095763088 and parameters: {'C': 0.0018470980497524553, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:37,600] Trial 19 finished with value: 0.8452840145982018 and parameters: {'C': 0.15422339746926925, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 7 with value: 0.8495807342171131.\n",
      "[I 2026-01-18 22:37:37,603] A new study created in memory with name: no-name-951ca692-52ae-46d9-b988-0afc205cbcf0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Logistic Regression: {'C': 0.4466241977543894, 'solver': 'lbfgs'}\n",
      "Optimizing Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:37:38,017] Trial 0 finished with value: 0.7982687805613418 and parameters: {'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 1, 'criterion': 'gini'}. Best is trial 0 with value: 0.7982687805613418.\n",
      "[I 2026-01-18 22:37:38,263] Trial 1 finished with value: 0.7889058459183064 and parameters: {'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'entropy'}. Best is trial 0 with value: 0.7982687805613418.\n",
      "[I 2026-01-18 22:37:38,570] Trial 2 finished with value: 0.8033521920254876 and parameters: {'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:38,923] Trial 3 finished with value: 0.8023318319613008 and parameters: {'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:39,344] Trial 4 finished with value: 0.7854454798887633 and parameters: {'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:39,661] Trial 5 finished with value: 0.7992126875494077 and parameters: {'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 17, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:40,070] Trial 6 finished with value: 0.7884697294436093 and parameters: {'max_depth': 19, 'min_samples_split': 15, 'min_samples_leaf': 3, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:40,430] Trial 7 finished with value: 0.8023318319613008 and parameters: {'max_depth': 29, 'min_samples_split': 12, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 2 with value: 0.8033521920254876.\n",
      "[I 2026-01-18 22:37:40,834] Trial 8 finished with value: 0.8094371481163062 and parameters: {'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 5, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:41,200] Trial 9 finished with value: 0.7993272866389298 and parameters: {'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 15, 'criterion': 'gini'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:41,630] Trial 10 finished with value: 0.8069013168613426 and parameters: {'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:42,032] Trial 11 finished with value: 0.8052855429330679 and parameters: {'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:42,463] Trial 12 finished with value: 0.8034988516277781 and parameters: {'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:42,652] Trial 13 finished with value: 0.7595717946542664 and parameters: {'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 11, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:43,086] Trial 14 finished with value: 0.8011344334247852 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 7, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:43,519] Trial 15 finished with value: 0.7926747456390637 and parameters: {'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 13, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:43,902] Trial 16 finished with value: 0.8052832682943596 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 7, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:44,322] Trial 17 finished with value: 0.796670616390182 and parameters: {'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 20, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:44,804] Trial 18 finished with value: 0.7923246839469489 and parameters: {'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:45,242] Trial 19 finished with value: 0.8048410370022007 and parameters: {'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 11, 'criterion': 'entropy'}. Best is trial 8 with value: 0.8094371481163062.\n",
      "[I 2026-01-18 22:37:45,243] A new study created in memory with name: no-name-00c2b59d-66a3-4c2e-a937-30f44466a9b0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Decision Tree: {'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 5, 'criterion': 'entropy'}\n",
      "Optimizing RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:37:47,382] Trial 0 finished with value: 0.8201084099111147 and parameters: {'n_estimators': 221, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.8201084099111147.\n",
      "[I 2026-01-18 22:37:49,500] Trial 1 finished with value: 0.8294536024434916 and parameters: {'n_estimators': 211, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.8294536024434916.\n",
      "[I 2026-01-18 22:37:52,069] Trial 2 finished with value: 0.8438888836012026 and parameters: {'n_estimators': 264, 'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:37:54,381] Trial 3 finished with value: 0.8396929131705587 and parameters: {'n_estimators': 233, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:37:56,246] Trial 4 finished with value: 0.8265538111840902 and parameters: {'n_estimators': 186, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:37:57,926] Trial 5 finished with value: 0.8136323807590159 and parameters: {'n_estimators': 164, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:37:58,673] Trial 6 finished with value: 0.8086936512726505 and parameters: {'n_estimators': 60, 'max_depth': 31, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:00,999] Trial 7 finished with value: 0.8217365934311264 and parameters: {'n_estimators': 233, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:03,964] Trial 8 finished with value: 0.7937400382240899 and parameters: {'n_estimators': 295, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:05,524] Trial 9 finished with value: 0.8103217152003817 and parameters: {'n_estimators': 153, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:08,400] Trial 10 finished with value: 0.8395250384367339 and parameters: {'n_estimators': 294, 'max_depth': 23, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:10,986] Trial 11 finished with value: 0.8089636170756466 and parameters: {'n_estimators': 257, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:13,531] Trial 12 finished with value: 0.8355283356327255 and parameters: {'n_estimators': 260, 'max_depth': 22, 'min_samples_split': 14, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:14,786] Trial 13 finished with value: 0.8317292849639873 and parameters: {'n_estimators': 116, 'max_depth': 10, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:17,338] Trial 14 finished with value: 0.8377903467510146 and parameters: {'n_estimators': 258, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:19,361] Trial 15 finished with value: 0.8373684863196665 and parameters: {'n_estimators': 188, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:20,715] Trial 16 finished with value: 0.7632930046532952 and parameters: {'n_estimators': 132, 'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 12}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:23,064] Trial 17 finished with value: 0.8332437616649266 and parameters: {'n_estimators': 238, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.8438888836012026.\n",
      "[I 2026-01-18 22:38:25,762] Trial 18 finished with value: 0.8458849058903503 and parameters: {'n_estimators': 267, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.8458849058903503.\n",
      "[I 2026-01-18 22:38:28,541] Trial 19 finished with value: 0.8472191453518367 and parameters: {'n_estimators': 277, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.8472191453518367.\n",
      "[I 2026-01-18 22:38:28,544] A new study created in memory with name: no-name-5c219883-e50f-4b4d-8cf0-51e9847a5a51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for RandomForest: {'n_estimators': 277, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3}\n",
      "Optimizing XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:38:31,344] Trial 0 finished with value: 0.8118553019746582 and parameters: {'n_estimators': 209, 'max_depth': 3, 'learning_rate': 0.013212610087695259, 'subsample': 0.6031807987779823, 'colsample_bytree': 0.8867138189072564, 'gamma': 3.7652064537964014}. Best is trial 0 with value: 0.8118553019746582.\n",
      "[I 2026-01-18 22:38:32,246] Trial 1 finished with value: 0.8548544745341395 and parameters: {'n_estimators': 278, 'max_depth': 3, 'learning_rate': 0.19810939323433518, 'subsample': 0.9057940286097972, 'colsample_bytree': 0.5236719659959407, 'gamma': 0.28741585743546183}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:32,639] Trial 2 finished with value: 0.8463862884374396 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.19897916332496962, 'subsample': 0.7056579728870793, 'colsample_bytree': 0.7611182624379897, 'gamma': 4.4231710572063205}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:33,031] Trial 3 finished with value: 0.8458532922873901 and parameters: {'n_estimators': 85, 'max_depth': 6, 'learning_rate': 0.19674669091251823, 'subsample': 0.6706698172790755, 'colsample_bytree': 0.7633836761862931, 'gamma': 4.219638427328106}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:33,343] Trial 4 finished with value: 0.8359742470951628 and parameters: {'n_estimators': 58, 'max_depth': 3, 'learning_rate': 0.22895490927791892, 'subsample': 0.6726712466935403, 'colsample_bytree': 0.7795770753429739, 'gamma': 4.543719502686335}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:33,735] Trial 5 finished with value: 0.8438487299356292 and parameters: {'n_estimators': 65, 'max_depth': 10, 'learning_rate': 0.2164452755902954, 'subsample': 0.889790429225949, 'colsample_bytree': 0.5118465122833304, 'gamma': 3.716824375548456}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:34,320] Trial 6 finished with value: 0.8506321127761396 and parameters: {'n_estimators': 115, 'max_depth': 11, 'learning_rate': 0.20477365381887994, 'subsample': 0.5918004941291094, 'colsample_bytree': 0.9621806250952629, 'gamma': 3.2793085586388786}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:35,073] Trial 7 finished with value: 0.8532925791130633 and parameters: {'n_estimators': 185, 'max_depth': 4, 'learning_rate': 0.1264646850804784, 'subsample': 0.8283974143868502, 'colsample_bytree': 0.5218269945708547, 'gamma': 1.5257100217242747}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:35,794] Trial 8 finished with value: 0.7853920927715105 and parameters: {'n_estimators': 220, 'max_depth': 2, 'learning_rate': 0.01269049759974693, 'subsample': 0.9272191470199311, 'colsample_bytree': 0.7405335485195106, 'gamma': 4.320656564506625}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:37,349] Trial 9 finished with value: 0.8377115510967902 and parameters: {'n_estimators': 251, 'max_depth': 7, 'learning_rate': 0.010036634542689018, 'subsample': 0.5683982290547037, 'colsample_bytree': 0.5570898444918455, 'gamma': 0.6169913422754275}. Best is trial 1 with value: 0.8548544745341395.\n",
      "[I 2026-01-18 22:38:39,298] Trial 10 finished with value: 0.8557940781403331 and parameters: {'n_estimators': 285, 'max_depth': 8, 'learning_rate': 0.07109483005304434, 'subsample': 0.9753820035653417, 'colsample_bytree': 0.6363615116033594, 'gamma': 0.050575121538290524}. Best is trial 10 with value: 0.8557940781403331.\n",
      "[I 2026-01-18 22:38:41,245] Trial 11 finished with value: 0.8590316424733744 and parameters: {'n_estimators': 293, 'max_depth': 8, 'learning_rate': 0.0590157327638824, 'subsample': 0.9731692515217322, 'colsample_bytree': 0.6343223890807868, 'gamma': 0.03480883239539384}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:42,351] Trial 12 finished with value: 0.8559383459480076 and parameters: {'n_estimators': 299, 'max_depth': 9, 'learning_rate': 0.05006385637836373, 'subsample': 0.9955069590345239, 'colsample_bytree': 0.6395730604971668, 'gamma': 1.4176461246263468}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:43,919] Trial 13 finished with value: 0.8583718955250995 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.0342087791298205, 'subsample': 0.8138892617530813, 'colsample_bytree': 0.6404588499836497, 'gamma': 1.7474944148346188}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:45,345] Trial 14 finished with value: 0.853793720542574 and parameters: {'n_estimators': 244, 'max_depth': 12, 'learning_rate': 0.02836180716923238, 'subsample': 0.8007910679228679, 'colsample_bytree': 0.6481592540969306, 'gamma': 2.3569835085982707}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:46,842] Trial 15 finished with value: 0.8575783468840782 and parameters: {'n_estimators': 257, 'max_depth': 8, 'learning_rate': 0.03213150233488293, 'subsample': 0.8003208733344338, 'colsample_bytree': 0.6008669186871888, 'gamma': 1.1650958518870342}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:47,610] Trial 16 finished with value: 0.8533091620838577 and parameters: {'n_estimators': 140, 'max_depth': 10, 'learning_rate': 0.07658371245199413, 'subsample': 0.5089294138899969, 'colsample_bytree': 0.7026894047250871, 'gamma': 2.3398090860720755}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:48,609] Trial 17 finished with value: 0.8460338158315265 and parameters: {'n_estimators': 160, 'max_depth': 7, 'learning_rate': 0.023906914645718955, 'subsample': 0.8432624638635724, 'colsample_bytree': 0.844044786849023, 'gamma': 2.936258705436612}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:50,008] Trial 18 finished with value: 0.8571708149957352 and parameters: {'n_estimators': 228, 'max_depth': 9, 'learning_rate': 0.041832468960241724, 'subsample': 0.739631897821947, 'colsample_bytree': 0.694589933606333, 'gamma': 1.897869684586608}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:51,000] Trial 19 finished with value: 0.855565506871205 and parameters: {'n_estimators': 275, 'max_depth': 6, 'learning_rate': 0.09256262370766932, 'subsample': 0.9485636868999063, 'colsample_bytree': 0.5895483061802168, 'gamma': 0.8215949758095239}. Best is trial 11 with value: 0.8590316424733744.\n",
      "[I 2026-01-18 22:38:51,003] A new study created in memory with name: no-name-6b999266-be73-44c0-9975-42d56ebbf831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for XGBoost: {'n_estimators': 293, 'max_depth': 8, 'learning_rate': 0.0590157327638824, 'subsample': 0.9731692515217322, 'colsample_bytree': 0.6343223890807868, 'gamma': 0.03480883239539384}\n",
      "Optimizing CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-18 22:38:58,637] Trial 0 finished with value: 0.8493852487723764 and parameters: {'iterations': 491, 'depth': 5, 'learning_rate': 0.17120235890950528, 'l2_leaf_reg': 6}. Best is trial 0 with value: 0.8493852487723764.\n",
      "[I 2026-01-18 22:39:28,574] Trial 1 finished with value: 0.8573670814319502 and parameters: {'iterations': 460, 'depth': 10, 'learning_rate': 0.0473800970237041, 'l2_leaf_reg': 4}. Best is trial 1 with value: 0.8573670814319502.\n",
      "[I 2026-01-18 22:39:35,917] Trial 2 finished with value: 0.8547447608700459 and parameters: {'iterations': 412, 'depth': 6, 'learning_rate': 0.01416723594102277, 'l2_leaf_reg': 3}. Best is trial 1 with value: 0.8573670814319502.\n",
      "[I 2026-01-18 22:39:45,012] Trial 3 finished with value: 0.8413840031361394 and parameters: {'iterations': 221, 'depth': 9, 'learning_rate': 0.010705276446961008, 'l2_leaf_reg': 9}. Best is trial 1 with value: 0.8573670814319502.\n",
      "[I 2026-01-18 22:39:46,335] Trial 4 finished with value: 0.8545160395001314 and parameters: {'iterations': 64, 'depth': 6, 'learning_rate': 0.24267152291820676, 'l2_leaf_reg': 5}. Best is trial 1 with value: 0.8573670814319502.\n",
      "[I 2026-01-18 22:39:53,112] Trial 5 finished with value: 0.857526773909013 and parameters: {'iterations': 487, 'depth': 5, 'learning_rate': 0.025195775797587364, 'l2_leaf_reg': 5}. Best is trial 5 with value: 0.857526773909013.\n",
      "[I 2026-01-18 22:40:01,843] Trial 6 finished with value: 0.8544892830632386 and parameters: {'iterations': 439, 'depth': 7, 'learning_rate': 0.08684480320224251, 'l2_leaf_reg': 8}. Best is trial 5 with value: 0.857526773909013.\n",
      "[I 2026-01-18 22:40:06,967] Trial 7 finished with value: 0.8506187741667155 and parameters: {'iterations': 436, 'depth': 4, 'learning_rate': 0.2688296148187267, 'l2_leaf_reg': 6}. Best is trial 5 with value: 0.857526773909013.\n",
      "[I 2026-01-18 22:40:14,537] Trial 8 finished with value: 0.8543904191071903 and parameters: {'iterations': 458, 'depth': 6, 'learning_rate': 0.1521375730353696, 'l2_leaf_reg': 7}. Best is trial 5 with value: 0.857526773909013.\n",
      "[I 2026-01-18 22:40:20,686] Trial 9 finished with value: 0.8577113266269113 and parameters: {'iterations': 217, 'depth': 8, 'learning_rate': 0.0582718612397974, 'l2_leaf_reg': 4}. Best is trial 9 with value: 0.8577113266269113.\n",
      "[I 2026-01-18 22:40:27,418] Trial 10 finished with value: 0.860106373821003 and parameters: {'iterations': 239, 'depth': 8, 'learning_rate': 0.04625099285418157, 'l2_leaf_reg': 1}. Best is trial 10 with value: 0.860106373821003.\n",
      "[I 2026-01-18 22:40:34,528] Trial 11 finished with value: 0.8620568419236613 and parameters: {'iterations': 257, 'depth': 8, 'learning_rate': 0.044909869460020256, 'l2_leaf_reg': 1}. Best is trial 11 with value: 0.8620568419236613.\n",
      "[I 2026-01-18 22:40:43,392] Trial 12 finished with value: 0.8592773472312843 and parameters: {'iterations': 315, 'depth': 8, 'learning_rate': 0.03332110305806176, 'l2_leaf_reg': 1}. Best is trial 11 with value: 0.8620568419236613.\n",
      "[I 2026-01-18 22:40:52,075] Trial 13 finished with value: 0.8557502735135158 and parameters: {'iterations': 309, 'depth': 8, 'learning_rate': 0.08231024304017184, 'l2_leaf_reg': 1}. Best is trial 11 with value: 0.8620568419236613.\n",
      "[I 2026-01-18 22:41:00,910] Trial 14 finished with value: 0.8535212103283042 and parameters: {'iterations': 140, 'depth': 10, 'learning_rate': 0.02390677574324642, 'l2_leaf_reg': 2}. Best is trial 11 with value: 0.8620568419236613.\n",
      "[I 2026-01-18 22:41:10,915] Trial 15 finished with value: 0.86230332088533 and parameters: {'iterations': 233, 'depth': 9, 'learning_rate': 0.03910059253612287, 'l2_leaf_reg': 2}. Best is trial 15 with value: 0.86230332088533.\n",
      "[I 2026-01-18 22:41:26,195] Trial 16 finished with value: 0.8578910223256425 and parameters: {'iterations': 361, 'depth': 9, 'learning_rate': 0.02143447289708496, 'l2_leaf_reg': 3}. Best is trial 15 with value: 0.86230332088533.\n",
      "[I 2026-01-18 22:41:32,740] Trial 17 finished with value: 0.8584270064121587 and parameters: {'iterations': 145, 'depth': 9, 'learning_rate': 0.08298136457535249, 'l2_leaf_reg': 2}. Best is trial 15 with value: 0.86230332088533.\n",
      "[I 2026-01-18 22:41:36,585] Trial 18 finished with value: 0.8521110226050393 and parameters: {'iterations': 173, 'depth': 7, 'learning_rate': 0.03327097028677362, 'l2_leaf_reg': 10}. Best is trial 15 with value: 0.86230332088533.\n",
      "[I 2026-01-18 22:41:55,800] Trial 19 finished with value: 0.8569208782306438 and parameters: {'iterations': 280, 'depth': 10, 'learning_rate': 0.016461737619156907, 'l2_leaf_reg': 2}. Best is trial 15 with value: 0.86230332088533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for CatBoost: {'iterations': 233, 'depth': 9, 'learning_rate': 0.03910059253612287, 'l2_leaf_reg': 2}\n",
      "\n",
      "Optimization Complete.\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_params = {}\n",
    "\n",
    "studies = {\n",
    "    'Logistic Regression': objective_lr,\n",
    "    'Decision Tree': objective_dt,\n",
    "    'RandomForest': objective_rf,\n",
    "    'XGBoost': objective_xgb,\n",
    "    'CatBoost': objective_cat\n",
    "}\n",
    "\n",
    "for name, objective in studies.items():\n",
    "    print(f\"Optimizing {name}...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=20) # 20 trials for demonstration\n",
    "    \n",
    "    print(f\"Best params for {name}: {study.best_params}\")\n",
    "    best_models[name] = study.best_trial.value\n",
    "    best_params[name] = study.best_params\n",
    "    \n",
    "print(\"\\nOptimization Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Best Models and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.7821, F1: 0.6008\n",
      "Training best Decision Tree...\n",
      "Decision Tree - Accuracy: 0.7438, F1: 0.5738\n",
      "Training best RandomForest...\n",
      "RandomForest - Accuracy: 0.7715, F1: 0.6064\n",
      "Training best XGBoost...\n",
      "XGBoost - Accuracy: 0.7779, F1: 0.5876\n",
      "Training best CatBoost...\n",
      "CatBoost - Accuracy: 0.7835, F1: 0.6044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.782115</td>\n",
       "      <td>0.600780</td>\n",
       "      <td>{'C': 0.4466241977543894, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.743790</td>\n",
       "      <td>0.573790</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 17, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.771469</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>{'n_estimators': 277, 'max_depth': 20, 'min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.777857</td>\n",
       "      <td>0.587615</td>\n",
       "      <td>{'n_estimators': 293, 'max_depth': 8, 'learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.783534</td>\n",
       "      <td>0.604410</td>\n",
       "      <td>{'iterations': 233, 'depth': 9, 'learning_rate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score  \\\n",
       "0  Logistic Regression  0.782115  0.600780   \n",
       "1        Decision Tree  0.743790  0.573790   \n",
       "2         RandomForest  0.771469  0.606357   \n",
       "3              XGBoost  0.777857  0.587615   \n",
       "4             CatBoost  0.783534  0.604410   \n",
       "\n",
       "                                         Best Params  \n",
       "0       {'C': 0.4466241977543894, 'solver': 'lbfgs'}  \n",
       "1  {'max_depth': 10, 'min_samples_split': 17, 'mi...  \n",
       "2  {'n_estimators': 277, 'max_depth': 20, 'min_sa...  \n",
       "3  {'n_estimators': 293, 'max_depth': 8, 'learnin...  \n",
       "4  {'iterations': 233, 'depth': 9, 'learning_rate...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, params in best_params.items():\n",
    "    print(f\"Training best {name}...\")\n",
    "    if name == 'Logistic Regression':\n",
    "        solver = params['solver']\n",
    "        penalty = 'l2' # Default penalty\n",
    "        l1_ratio = None\n",
    "        \n",
    "        if solver == 'lbfgs': \n",
    "            penalty = 'l2'\n",
    "            l1_ratio = None\n",
    "        elif solver == 'liblinear':\n",
    "             penalty = params.get('penalty_liblinear', 'l2') \n",
    "        elif solver == 'saga':\n",
    "             penalty = params.get('penalty_saga', 'l2')\n",
    "\n",
    "        # Handle l1_ratio for elasticnet if applicable\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = params.get('l1_ratio')\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            C=params['C'], \n",
    "            solver=solver, \n",
    "            penalty=penalty, \n",
    "            l1_ratio=l1_ratio,\n",
    "            random_state=RANDOM_STATE, \n",
    "            max_iter=1000\n",
    "        )\n",
    "    elif name == 'Decision Tree':\n",
    "        clf = DecisionTreeClassifier(**params, random_state=RANDOM_STATE)\n",
    "    elif name == 'RandomForest':\n",
    "        clf = RandomForestClassifier(**params, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    elif name == 'XGBoost':\n",
    "        clf = XGBClassifier(**params, random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False, n_jobs=-1)\n",
    "    elif name == 'CatBoost':\n",
    "        clf = CatBoostClassifier(**params, random_seed=RANDOM_STATE, verbose=0, thread_count=-1)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Best Params': str(params)\n",
    "    })\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# Visualize F1 Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='F1 Score', y='Model', data=results_df, palette='viridis')\n",
    "plt.title('Model Performance after Optuna Tuning (F1 Score)')\n",
    "plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
